{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/sonar_train.data\", header=None).values\n",
    "valid_data = pd.read_csv(\"./data/sonar_valid.data\", header=None).values\n",
    "test_data = pd.read_csv('./data/sonar_test.data', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 60) (104,)\n",
      "(52, 60) (52,)\n",
      "(52, 60) (52,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = train_data[:,:-1], train_data[:,-1]\n",
    "train_y = np.where(train_y == 2, -1.0, 1.0)\n",
    "print(train_x.shape, train_y.shape)\n",
    "\n",
    "valid_x, valid_y = valid_data[:,:-1], valid_data[:,-1]\n",
    "valid_y = np.where(valid_y == 2, -1.0, 1.0)\n",
    "print(valid_x.shape, valid_y.shape)\n",
    "\n",
    "test_x, test_y = test_data[:,:-1], test_data[:,-1]\n",
    "test_y = np.where(test_y == 2, -1.0, 1.0)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = scaler.transform(train_x)\n",
    "valid_x = scaler.transform(valid_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1(object):\n",
    "    def __init__(self, coeff):\n",
    "        self.coeff = coeff\n",
    "        \n",
    "    def __call__(self, w):\n",
    "        return self.coeff*np.sum(np.abs(w))\n",
    "    \n",
    "    def grad(self, w):\n",
    "        return self.coeff*np.sign(w)\n",
    "    \n",
    "class L2(object):\n",
    "    def __init__(self, coeff):\n",
    "        self.coeff = coeff\n",
    "        \n",
    "    def __call__(self, w):\n",
    "        return 0.5*self.coeff*np.dot(w.T,w)[0]\n",
    "    \n",
    "    def grad(self, w):\n",
    "        return self.coeff*w\n",
    "    \n",
    "class Sigmoid(object):\n",
    "    def __call__(self, x):\n",
    "        # Numerically stable sigmoid\n",
    "        return np.where(x >= 0,\n",
    "                    1 / (1 + np.exp(-x)),\n",
    "                    np.exp(x) / (1 + np.exp(x)))\n",
    "    \n",
    "    def grad(self, x):\n",
    "        return self(x)*(1-self(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestValue(object):\n",
    "    def __init__(self, init_value=-np.inf, monitor_type=\"min\"):\n",
    "        assert monitor_type in (\"min\", \"max\")\n",
    "        self.best_value = init_value\n",
    "        self.monitor_type = monitor_type\n",
    "        \n",
    "    def update(self, value, model=None, **kwargs):\n",
    "        if self.monitor_type == \"max\":\n",
    "            if value > self.best_value:\n",
    "                self.best_value = value\n",
    "                self.additional_params = kwargs\n",
    "                self.best_model = deepcopy(model)\n",
    "        else:\n",
    "            if value < self.best_value:\n",
    "                self.best_value = value\n",
    "                self.additional_params = kwargs\n",
    "                self.best_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(BaseEstimator):\n",
    "    # probabilistic approach\n",
    "    # y must be 1 or -1\n",
    "    def __init__(self, regularizer=None, coeff=0.0, lr=None, epochs=1000, valid_data=None, verbose=True):\n",
    "        if regularizer == \"l1\" or isinstance(regularizer, L1):\n",
    "            self.regularizer = L1(coeff)\n",
    "        elif regularizer == \"l2\" or isinstance(regularizer, L2):\n",
    "            self.regularizer = L2(coeff)\n",
    "        elif regularizer is None:\n",
    "            self.regularizer = None  # No regularization\n",
    "        else:\n",
    "            raise ValueError(\"regularizer must be one of 'l1', 'l2' or None. But got {}\".format(regularizer))\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.best_train_accuracy = BestValue(init_value=0.0, monitor_type=\"max\")\n",
    "        self.valid_data = valid_data\n",
    "        self.best_valid_accuracy = BestValue(init_value=0.0, monitor_type=\"max\")\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "        assert self.w.shape == (self.in_features, 1)\n",
    "        y = np.dot(x, self.w) + self.b\n",
    "        return np.squeeze(y, axis=1)\n",
    "        \n",
    "    def loss(self, x, y_true):\n",
    "        losses = ((y_true + 1)*self(x)/2 - np.log(1+np.exp(self(x))))\n",
    "        if self.regularizer is not None:\n",
    "            return np.sum(losses) - self.regularizer(self.w)\n",
    "        else:\n",
    "            return np.sum(losses)\n",
    "    \n",
    "    def calculate_grad(self, x, y_true):\n",
    "        self.db = np.sum((y_true+1)/2 - self.sigmoid(self(x)))\n",
    "        if self.regularizer is not None:\n",
    "            self.dw = np.sum(((y_true+1)/2 - self.sigmoid(self(x))).reshape(-1,1) * x, axis=0).reshape(-1, 1) - self.regularizer.grad(self.w)\n",
    "        else:\n",
    "            self.dw = np.sum(((y_true+1)/2 - self.sigmoid(self(x))).reshape(-1,1) * x, axis=0).reshape(-1, 1)\n",
    "        \n",
    "    def update(self, lr):\n",
    "        # gradient ascent\n",
    "        self.w = self.w + lr*self.dw\n",
    "        self.b = self.b + lr*self.db\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y_pred = self.sigmoid(self(x))\n",
    "        return np.where(y_pred>=0.5, 1, -1)\n",
    "    \n",
    "    def predict_best(self, x):\n",
    "        best_model = self.best_valid_accuracy.best_model\n",
    "        y_pred = self.sigmoid(best_model(x))\n",
    "        return np.where(y_pred>=0.5, 1, -1)\n",
    "        \n",
    "    def calculate_accuracy(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        return np.mean(np.equal(y.astype(np.float32), y_pred.astype(np.float32)))\n",
    "    \n",
    "    def calculate_best_accuracy(self, x, y):\n",
    "        y_pred = self.predict_best(x)\n",
    "        return np.mean(np.equal(y.astype(np.float32), y_pred.astype(np.float32)))\n",
    "    \n",
    "    def score(self, x=None, y=None):\n",
    "        # A bogus function for GridSearch to work\n",
    "        if self.valid_data is None:\n",
    "            return self.calculate_accuracy(x,y)\n",
    "        else:\n",
    "            return self.best_valid_accuracy.best_value\n",
    "    \n",
    "    def fit(self, train_x, train_y):\n",
    "        self.in_features = train_x.shape[1]\n",
    "        self.w = np.zeros((self.in_features, 1), dtype=np.float64)\n",
    "        self.b = np.zeros(1, dtype=np.float64)[0]\n",
    "        for i in range(1,self.epochs+1):\n",
    "            train_loss = self.loss(x=train_x, y_true=train_y)\n",
    "            self.calculate_grad(x=train_x, y_true=train_y)\n",
    "            if self.lr is None:\n",
    "                self.update(lr=2/(2+i))\n",
    "            else:\n",
    "                self.update(lr=self.lr)\n",
    "            train_accuracy = self.calculate_accuracy(train_x, train_y)\n",
    "            self.best_train_accuracy.update(train_accuracy, epoch=i, model = self, train_loss=train_loss)\n",
    "            if self.valid_data:\n",
    "                valid_loss = self.loss(x=self.valid_data[0],y_true=self.valid_data[1])\n",
    "                valid_accuracy = self.calculate_accuracy(self.valid_data[0], self.valid_data[1])\n",
    "                self.best_valid_accuracy.update(valid_accuracy, epoch=i, model = self, valid_loss=valid_loss)\n",
    "            else:\n",
    "                valid_accuracy=0.0\n",
    "                valid_loss = -np.inf\n",
    "            if self.verbose:\n",
    "                print(\"epoch {}/{}: Train Loss: {}, Validation_loss: {} Training accuracy: {}, Validation_accuracy: {}\".format(i, self.epochs, train_loss, valid_loss,train_accuracy, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 regularization Grid search for lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:04<00:03,  2.53it/s]C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:05<00:02,  2.56it/s]C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in multiply\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater_equal\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in greater_equal\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in subtract\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = BestValue(init_value=0.0, monitor_type=\"max\")\n",
    "for lmbda in tqdm([math.pow(10,i) for i in range(-10,10)]):\n",
    "    model = LogisticRegression(valid_data=(valid_x, valid_y), epochs=1000, verbose=False, regularizer=\"l2\", coeff=lmbda)\n",
    "    model.fit(train_x, train_y)\n",
    "    best_accuracy.update(model.score(), model=model, coeff=lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coeff': 100.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy.additional_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846153846153846"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_l2_regularized = best_accuracy.best_model.best_valid_accuracy.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07203429, -0.03166687, -0.0050325 , -0.03503327, -0.0011076 ,\n",
       "        0.01799703,  0.02137034,  0.00237779, -0.08505155, -0.07553474,\n",
       "       -0.10091746, -0.10870769, -0.08369476, -0.01337836,  0.01927269,\n",
       "        0.04159433,  0.04533289,  0.01636538, -0.03595391, -0.05750692,\n",
       "       -0.0426478 , -0.03495508, -0.04103151, -0.02012037,  0.01024837,\n",
       "        0.01660146, -0.00986387, -0.03063059, -0.02727321, -0.02284122,\n",
       "        0.01138676, -0.01993036,  0.00643682,  0.04378844,  0.07081256,\n",
       "        0.08809589,  0.07419586,  0.02212247,  0.0004961 ,  0.04591773,\n",
       "        0.0437021 ,  0.00974678, -0.05601843, -0.06866506, -0.05369865,\n",
       "       -0.03194237, -0.04522855, -0.06300298, -0.05832072,  0.00583477,\n",
       "       -0.06516521, -0.07073703, -0.02344132, -0.03595537,  0.02591752,\n",
       "       -0.03737281,  0.04061669, -0.04004346, -0.01883741, -0.01787745])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_l2_regularized.w.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18515319257436305"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_l2_regularized.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for l2 regularized = 0.7884615384615384\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = best_model_l2_regularized.calculate_accuracy(test_x, test_y)\n",
    "print(\"Test accuracy for l2 regularized = {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 regularization grid search for lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:04<00:02,  3.06it/s]C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Acer\\miniconda3\\envs\\ml_course\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "best_accuracy_l1 = BestValue(init_value=0.0, monitor_type=\"max\")\n",
    "for lmbda in tqdm([math.pow(10,i) for i in range(-10,10)]):\n",
    "    model = LogisticRegression(valid_data=(valid_x, valid_y), epochs=1000, verbose=False, regularizer=\"l1\", coeff=lmbda)\n",
    "    model.fit(train_x, train_y)\n",
    "    best_accuracy_l1.update(model.score(), model=model, coeff=lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coeff': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy_l1.additional_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9038461538461539"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy_l1.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l1_model = best_accuracy_l1.best_model.best_valid_accuracy.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7307692307692307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l1_model.calculate_accuracy(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01451205, -0.00562126, -0.01720734, -0.02977406, -0.03703174,\n",
       "        0.00634904,  0.02738394, -0.00334069, -0.02465461, -0.03212977,\n",
       "       -0.23064254, -0.17837461, -0.0015372 , -0.00514361,  0.01266242,\n",
       "        0.02507199,  0.0070222 , -0.0101527 , -0.02832369, -0.07241257,\n",
       "       -0.01449742, -0.03784816, -0.06239183, -0.02209457,  0.01491925,\n",
       "        0.01778565, -0.02055214, -0.00291438, -0.0076785 , -0.02606921,\n",
       "        0.02545161, -0.01658357,  0.01424691,  0.0110537 ,  0.0261303 ,\n",
       "        0.10989975,  0.04939839,  0.00630216,  0.02633256,  0.06555013,\n",
       "        0.00885936,  0.02552834, -0.0469365 , -0.02401955,  0.00472317,\n",
       "       -0.01095853, -0.044027  , -0.01265277, -0.01458956,  0.02128773,\n",
       "       -0.02102451, -0.01474456, -0.0298286 ,  0.01532888,  0.04309554,\n",
       "       -0.01982156,  0.01864155, -0.02562613,  0.02456804, -0.03329605])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l1_model.w.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0531693021143948"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l1_model.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(valid_data=(valid_x, valid_y), epochs=1000, verbose=False, regularizer=None)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_valid_accuracy.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884615384615384"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.calculate_best_accuracy(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
